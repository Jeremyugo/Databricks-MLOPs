{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "710c4ff6-22f2-4d27-af2c-cfae80091fd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Model Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25c59f15-028b-4526-b28a-70b023698fb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "use catalog main;\n",
    "\n",
    "use schema dbdemos_mlops;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1e38e04-24c6-4e6d-b749-faf5bce74a70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import DoubleType, StructField\n",
    "\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.catalog import (\n",
    "    MonitorInferenceLog,\n",
    "    MonitorInferenceLogProblemType,\n",
    "    MonitorMetric,\n",
    "    MonitorMetricType,\n",
    "    MonitorInfoStatus,\n",
    "    MonitorRefreshInfoState\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2138f179-d9d8-4e7f-9fe7-b700d8562ea7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### We need to Create an Inference Table\n",
    "\n",
    "the inference table will be used to store the inference and model data to detect data, label and model drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aec512d-2738-4052-85b3-822cb68ee7e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "\n",
    "model_name = f\"advanced_mlops_churn\"\n",
    "\n",
    "model = client.get_registered_model(name=model_name)\n",
    "model_version = int(client.get_model_version_by_alias(name=model_name, alias=\"Champion\").version)\n",
    "\n",
    "features_df = spark.read.table('advanced_churn_cust_ids')\n",
    "\n",
    "inference_df = (\n",
    "    features_df\n",
    "    .withColumn(\"prediction\", F.lit(None).cast('string'))\n",
    "    .withColumn(\"model_name\", F.lit(model_name)) \n",
    "    .withColumn(\"model_version\", F.lit(model_version)) \n",
    "    .withColumn(\"model_alias\", F.lit(\"Champion\")) \n",
    "    .withColumn(\"inference_timestamp\", F.lit(datetime.now()- timedelta(days=2)))\n",
    ")\n",
    "\n",
    "inference_df.limit(0).write.mode('overwrite').saveAsTable('advanced_churn_inference_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73310ab2-7788-4253-a6eb-5a46182f974c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "ALTER TABLE advanced_churn_inference_table SET TBLPROPERTIES (delta.enableChangeDataFeed = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b28b6bae-7bf1-445a-afc7-ff2504d0422e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### We also need a Baseline Table\n",
    "\n",
    "this allows us to compare the inference, prediction and model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e2fc2a6-074c-4af8-9e51-1d3eba19cb6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "inference_df = spark.read.table(\"advanced_churn_cust_ids\")\n",
    "\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "model_name = f\"advanced_mlops_churn\"\n",
    "model_uri = f\"models:/{model_name}@Champion\"\n",
    "\n",
    "preds_df = fe.score_batch(df=inference_df, model_uri=model_uri, result_type=\"string\")\n",
    "display(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4eb215e3-fadd-4d43-93e5-a72dc3d2a42e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "baseline_df = preds_df.withColumn(\"model_name\", F.lit(model_name)) \\\n",
    "                              .withColumn(\"model_version\", F.lit(model_version)) \\\n",
    "\n",
    "baseline_df = baseline_df.drop('customer_id', 'transaction_ts')\n",
    "\n",
    "baseline_df.write.mode('overwrite').saveAsTable('advanced_churn_baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea20a4ee-ede5-4a37-9c05-2e749da9c283",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create a Custom metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0685ca24-3317-4f4b-b87b-791a8a40b5d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "expected_loss_metric = [\n",
    "  MonitorMetric(\n",
    "    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,\n",
    "    name=\"expected_loss\",\n",
    "    input_columns=[\":table\"],\n",
    "    definition=\"\"\"avg(CASE\n",
    "    WHEN {{prediction_col}} != {{label_col}} AND {{label_col}} = 'Yes' THEN -monthly_charges\n",
    "    ELSE 0 END\n",
    "    )\"\"\",\n",
    "    output_data_type= StructField(\"output\", DoubleType()).json()\n",
    "  )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64fed6c0-304e-4f33-98b0-2d1a7cfe63da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65a5f196-6019-4764-af25-b21f95849903",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "w = WorkspaceClient()\n",
    "\n",
    "try:\n",
    "  info = w.quality_monitors.create(\n",
    "    table_name=f\"main.dbdemos_mlops.advanced_churn_inference_table\",\n",
    "    inference_log=MonitorInferenceLog(\n",
    "            problem_type=MonitorInferenceLogProblemType.PROBLEM_TYPE_CLASSIFICATION,\n",
    "            prediction_col=\"prediction\",\n",
    "            timestamp_col=\"inference_timestamp\",\n",
    "            granularities=[\"1 day\"],\n",
    "            model_id_col=\"model_version\",\n",
    "            label_col=\"churn\", \n",
    "    ),\n",
    "    assets_dir=f\"{os.getcwd()}/monitoring\", \n",
    "    output_schema_name=f\"main.dbdemos_mlops\",\n",
    "    baseline_table_name=f\"main.dbdemos_mlops.advanced_churn_baseline\",\n",
    "    slicing_exprs=[\"senior_citizen='Yes'\", \"contract\"], \n",
    "    custom_metrics=expected_loss_metric)\n",
    "  \n",
    "except Exception as lhm_exception:\n",
    "  if \"already exist\" in str(lhm_exception).lower():\n",
    "    print(f\"Monitor for advanced_churn_inference_table already exists, retrieving monitor info:\")\n",
    "    info = w.quality_monitors.get(table_name=f\"main.dbdemos_mlops.advanced_churn_inference_table\")\n",
    "  else:\n",
    "    raise lhm_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad10d773-1dc3-4aab-8f59-e2fddb1c4c2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "while info.status == MonitorInfoStatus.MONITOR_STATUS_PENDING:\n",
    "  info = w.quality_monitors.get(table_name=f\"main.dbdemos_mlops.advanced_churn_inference_table\")\n",
    "  time.sleep(10)\n",
    "\n",
    "assert info.status == MonitorInfoStatus.MONITOR_STATUS_ACTIVE, \"Error creating monitor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adc84583-c816-40a5-b988-5f449193e35a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_refreshes():\n",
    "  return w.quality_monitors.list_refreshes(table_name=f\"main.dbdemos_mlops.advanced_churn_inference_table\").refreshes\n",
    "\n",
    "refreshes = get_refreshes()\n",
    "if len(refreshes) == 0:\n",
    "  w.quality_monitors.run_refresh(table_name=f\"main.dbdemos_mlops.advanced_churn_inference_table\")\n",
    "  time.sleep(5)\n",
    "  refreshes = get_refreshes()\n",
    "\n",
    "run_info = refreshes[0]\n",
    "while run_info.state in (MonitorRefreshInfoState.PENDING, MonitorRefreshInfoState.RUNNING):\n",
    "  run_info = w.quality_monitors.get_refresh(table_name=f\"main.dbdemos_mlops.advanced_churn_inference_table\", refresh_id=run_info.refresh_id)\n",
    "  print(f\"waiting for refresh to complete {run_info.state}...\")\n",
    "  time.sleep(30)\n",
    "\n",
    "assert run_info.state == MonitorRefreshInfoState.SUCCESS, \"Monitor refresh failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88719b01-4ebb-4b0d-b9c0-76b7dba7e4b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "w.quality_monitors.get(table_name=f\"main.dbdemos_mlops.advanced_churn_inference_table\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8227244878768098,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_model_monitoring",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
